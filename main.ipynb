{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch==2.2.1+cu121 torchvision==0.17.1+cu121 -f https://download.pytorch.org/whl/torch_stable.html --no-cache-dir\n!pip install \"numpy<2\" --no-cache-dir\n!pip install dgl==2.4.0 -f https://data.dgl.ai/wheels/torch-2.2/cu121/repo.html --no-cache-dir","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T06:54:31.725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import argparse\nfrom functools import partial\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T06:54:31.725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport ssl\n\nimport dgl\n\nimport numpy as np\nimport torch\nfrom six.moves import urllib\nfrom torch.utils.data import DataLoader, Dataset\n\n\ndef download_file(dataset):\n    print(\"Start Downloading data: {}\".format(dataset))\n    url = \"https://s3.us-west-2.amazonaws.com/dgl-data/dataset/{}\".format(\n        dataset\n    )\n    print(\"Start Downloading File....\")\n    context = ssl._create_unverified_context()\n    data = urllib.request.urlopen(url, context=context)\n    with open(\"./data/{}\".format(dataset), \"wb\") as handle:\n        handle.write(data.read())\n\n\nclass SnapShotDataset(Dataset):\n    def __init__(self, path, npz_file):\n        if not os.path.exists(path + \"/\" + npz_file):\n            if not os.path.exists(path):\n                os.mkdir(path)\n            download_file(npz_file)\n        zipfile = np.load(path + \"/\" + npz_file)\n        self.x = zipfile[\"x\"]\n        self.y = zipfile[\"y\"]\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        return self.x[idx, ...], self.y[idx, ...]\n\n\ndef METR_LAGraphDataset():\n    if not os.path.exists(\"data/graph_la.bin\"):\n        if not os.path.exists(\"data\"):\n            os.mkdir(\"data\")\n        download_file(\"graph_la.bin\")\n    g, _ = dgl.load_graphs(\"data/graph_la.bin\")\n    return g[0]\n\n\nclass METR_LATrainDataset(SnapShotDataset):\n    def __init__(self):\n        super(METR_LATrainDataset, self).__init__(\"data\", \"metr_la_train.npz\")\n        self.mean = self.x[..., 0].mean()\n        self.std = self.x[..., 0].std()\n\n\nclass METR_LATestDataset(SnapShotDataset):\n    def __init__(self):\n        super(METR_LATestDataset, self).__init__(\"data\", \"metr_la_test.npz\")\n\n\nclass METR_LAValidDataset(SnapShotDataset):\n    def __init__(self):\n        super(METR_LAValidDataset, self).__init__(\"data\", \"metr_la_valid.npz\")\n\n\ndef PEMS_BAYGraphDataset():\n    if not os.path.exists(\"data/graph_bay.bin\"):\n        if not os.path.exists(\"data\"):\n            os.mkdir(\"data\")\n        download_file(\"graph_bay.bin\")\n    g, _ = dgl.load_graphs(\"data/graph_bay.bin\")\n    return g[0]\n\n\nclass PEMS_BAYTrainDataset(SnapShotDataset):\n    def __init__(self):\n        super(PEMS_BAYTrainDataset, self).__init__(\"data\", \"pems_bay_train.npz\")\n        self.mean = self.x[..., 0].mean()\n        self.std = self.x[..., 0].std()\n\n\nclass PEMS_BAYTestDataset(SnapShotDataset):\n    def __init__(self):\n        super(PEMS_BAYTestDataset, self).__init__(\"data\", \"pems_bay_test.npz\")\n\n\nclass PEMS_BAYValidDataset(SnapShotDataset):\n    def __init__(self):\n        super(PEMS_BAYValidDataset, self).__init__(\"data\", \"pems_bay_valid.npz\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T06:54:31.725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import dgl\nimport dgl.function as fn\nimport numpy as np\nimport scipy.sparse as sparse\nimport torch\nimport torch.nn as nn\nfrom dgl.base import DGLError\n\n\nclass DiffConv(nn.Module):\n    \"\"\"DiffConv is the implementation of diffusion convolution from paper DCRNN\n    It will compute multiple diffusion matrix and perform multiple diffusion conv on it,\n    this layer can be used for traffic prediction, pedamic model.\n    Parameter\n    ==========\n    in_feats : int\n        number of input feature\n\n    out_feats : int\n        number of output feature\n\n    k : int\n        number of diffusion steps\n\n    dir : str [both/in/out]\n        direction of diffusion convolution\n        From paper default both direction\n    \"\"\"\n\n    def __init__(\n        self, in_feats, out_feats, k, in_graph_list, out_graph_list, dir=\"both\"\n    ):\n        super(DiffConv, self).__init__()\n        self.in_feats = in_feats\n        self.out_feats = out_feats\n        self.k = k\n        self.dir = dir\n        self.num_graphs = self.k - 1 if self.dir == \"both\" else 2 * self.k - 2\n        self.project_fcs = nn.ModuleList()\n        for i in range(self.num_graphs):\n            self.project_fcs.append(\n                nn.Linear(self.in_feats, self.out_feats, bias=False)\n            )\n        self.merger = nn.Parameter(torch.randn(self.num_graphs + 1))\n        self.in_graph_list = in_graph_list\n        self.out_graph_list = out_graph_list\n\n    @staticmethod\n    def attach_graph(g, k):\n        device = g.device\n        out_graph_list = []\n        in_graph_list = []\n        wadj, ind, outd = DiffConv.get_weight_matrix(g)\n        adj = sparse.coo_matrix(wadj / outd.cpu().numpy())\n        outg = dgl.from_scipy(adj, eweight_name=\"weight\").to(device)\n        outg.edata[\"weight\"] = outg.edata[\"weight\"].float().to(device)\n        out_graph_list.append(outg)\n        for i in range(k - 1):\n            out_graph_list.append(\n                DiffConv.diffuse(out_graph_list[-1], wadj, outd)\n            )\n        adj = sparse.coo_matrix(wadj.T / ind.cpu().numpy())\n        ing = dgl.from_scipy(adj, eweight_name=\"weight\").to(device)\n        ing.edata[\"weight\"] = ing.edata[\"weight\"].float().to(device)\n        in_graph_list.append(ing)\n        for i in range(k - 1):\n            in_graph_list.append(\n                DiffConv.diffuse(in_graph_list[-1], wadj.T, ind)\n            )\n        return out_graph_list, in_graph_list\n\n    @staticmethod\n    def get_weight_matrix(g):\n        adj = g.adj_external(scipy_fmt=\"coo\")\n        ind = g.in_degrees()\n        outd = g.out_degrees()\n        weight = g.edata[\"weight\"]\n        adj.data = weight.cpu().numpy()\n        return adj, ind, outd\n\n    @staticmethod\n    def diffuse(progress_g, weighted_adj, degree):\n        device = progress_g.device\n        progress_adj = progress_g.adj_external(scipy_fmt=\"coo\")\n        progress_adj.data = progress_g.edata[\"weight\"].cpu().numpy()\n        ret_adj = sparse.coo_matrix(\n            progress_adj @ (weighted_adj / degree.cpu().numpy())\n        )\n        ret_graph = dgl.from_scipy(ret_adj, eweight_name=\"weight\").to(device)\n        ret_graph.edata[\"weight\"] = ret_graph.edata[\"weight\"].float().to(device)\n        return ret_graph\n\n    def forward(self, g, x):\n        feat_list = []\n        if self.dir == \"both\":\n            graph_list = self.in_graph_list + self.out_graph_list\n        elif self.dir == \"in\":\n            graph_list = self.in_graph_list\n        elif self.dir == \"out\":\n            graph_list = self.out_graph_list\n\n        for i in range(self.num_graphs):\n            g = graph_list[i]\n            with g.local_scope():\n                g.ndata[\"n\"] = self.project_fcs[i](x)\n                g.update_all(\n                    fn.u_mul_e(\"n\", \"weight\", \"e\"), fn.sum(\"e\", \"feat\")\n                )\n                feat_list.append(g.ndata[\"feat\"])\n                # Each feat has shape [N,q_feats]\n        feat_list.append(self.project_fcs[-1](x))\n        feat_list = torch.cat(feat_list).view(\n            len(feat_list), -1, self.out_feats\n        )\n        ret = (\n            (self.merger * feat_list.permute(1, 2, 0)).permute(2, 0, 1).mean(0)\n        )\n        return ret\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T06:54:31.725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import dgl\nimport dgl.function as fn\nimport dgl.nn as dglnn\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom dgl.base import DGLError\nfrom dgl.nn.functional import edge_softmax\n\n\nclass WeightedGATConv(dglnn.GATConv):\n    \"\"\"\n    This model inherit from dgl GATConv for traffic prediction task,\n    it add edge weight when aggregating the node feature.\n    \"\"\"\n\n    def forward(self, graph, feat, get_attention=False):\n        with graph.local_scope():\n            if not self._allow_zero_in_degree:\n                if (graph.in_degrees() == 0).any():\n                    raise DGLError(\n                        \"There are 0-in-degree nodes in the graph, \"\n                        \"output for those nodes will be invalid. \"\n                        \"This is harmful for some applications, \"\n                        \"causing silent performance regression. \"\n                        \"Adding self-loop on the input graph by \"\n                        \"calling `g = dgl.add_self_loop(g)` will resolve \"\n                        \"the issue. Setting ``allow_zero_in_degree`` \"\n                        \"to be `True` when constructing this module will \"\n                        \"suppress the check and let the code run.\"\n                    )\n\n            if isinstance(feat, tuple):\n                h_src = self.feat_drop(feat[0])\n                h_dst = self.feat_drop(feat[1])\n                if not hasattr(self, \"fc_src\"):\n                    feat_src = self.fc(h_src).view(\n                        -1, self._num_heads, self._out_feats\n                    )\n                    feat_dst = self.fc(h_dst).view(\n                        -1, self._num_heads, self._out_feats\n                    )\n                else:\n                    feat_src = self.fc_src(h_src).view(\n                        -1, self._num_heads, self._out_feats\n                    )\n                    feat_dst = self.fc_dst(h_dst).view(\n                        -1, self._num_heads, self._out_feats\n                    )\n            else:\n                h_src = h_dst = self.feat_drop(feat)\n                feat_src = feat_dst = self.fc(h_src).view(\n                    -1, self._num_heads, self._out_feats\n                )\n                if graph.is_block:\n                    feat_dst = feat_src[: graph.number_of_dst_nodes()]\n            # NOTE: GAT paper uses \"first concatenation then linear projection\"\n            # to compute attention scores, while ours is \"first projection then\n            # addition\", the two approaches are mathematically equivalent:\n            # We decompose the weight vector a mentioned in the paper into\n            # [a_l || a_r], then\n            # a^T [Wh_i || Wh_j] = a_l Wh_i + a_r Wh_j\n            # Our implementation is much efficient because we do not need to\n            # save [Wh_i || Wh_j] on edges, which is not memory-efficient. Plus,\n            # addition could be optimized with DGL's built-in function u_add_v,\n            # which further speeds up computation and saves memory footprint.\n            el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1)\n            er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1)\n            graph.srcdata.update({\"ft\": feat_src, \"el\": el})\n            graph.dstdata.update({\"er\": er})\n            # compute edge attention, el and er are a_l Wh_i and a_r Wh_j respectively.\n            graph.apply_edges(fn.u_add_v(\"el\", \"er\", \"e\"))\n            e = self.leaky_relu(graph.edata.pop(\"e\"))\n            # compute softmax\n            graph.edata[\"a\"] = self.attn_drop(edge_softmax(graph, e))\n            # compute weighted attention\n            graph.edata[\"a\"] = (\n                graph.edata[\"a\"].permute(1, 2, 0) * graph.edata[\"weight\"]\n            ).permute(2, 0, 1)\n            # message passing\n            graph.update_all(fn.u_mul_e(\"ft\", \"a\", \"m\"), fn.sum(\"m\", \"ft\"))\n            rst = graph.dstdata[\"ft\"]\n            # residual\n            if self.res_fc is not None:\n                resval = self.res_fc(h_dst).view(\n                    h_dst.shape[0], -1, self._out_feats\n                )\n                rst = rst + resval\n            # activation\n            if self.activation:\n                rst = self.activation(rst)\n\n            if get_attention:\n                return rst, graph.edata[\"a\"]\n            else:\n                return rst\n\n\nclass GatedGAT(nn.Module):\n    \"\"\"Gated Graph Attention module, it is a general purpose\n    graph attention module proposed in paper GaAN. The paper use\n    it for traffic prediction task\n    Parameter\n    ==========\n    in_feats : int\n        number of input feature\n\n    out_feats : int\n        number of output feature\n\n    map_feats : int\n        intermediate feature size for gate computation\n\n    num_heads : int\n        number of head for multihead attention\n    \"\"\"\n\n    def __init__(self, in_feats, out_feats, map_feats, num_heads):\n        super(GatedGAT, self).__init__()\n        self.in_feats = in_feats\n        self.out_feats = out_feats\n        self.map_feats = map_feats\n        self.num_heads = num_heads\n        self.gatlayer = WeightedGATConv(\n            self.in_feats, self.out_feats, self.num_heads\n        )\n        self.gate_fn = nn.Linear(\n            2 * self.in_feats + self.map_feats, self.num_heads\n        )\n        self.gate_m = nn.Linear(self.in_feats, self.map_feats)\n        self.merger_layer = nn.Linear(\n            self.in_feats + self.out_feats, self.out_feats\n        )\n\n    def forward(self, g, x):\n        with g.local_scope():\n            g.ndata[\"x\"] = x\n            g.ndata[\"z\"] = self.gate_m(x)\n            g.update_all(fn.copy_u(\"x\", \"x\"), fn.mean(\"x\", \"mean_z\"))\n            g.update_all(fn.copy_u(\"z\", \"z\"), fn.max(\"z\", \"max_z\"))\n            nft = torch.cat(\n                [g.ndata[\"x\"], g.ndata[\"max_z\"], g.ndata[\"mean_z\"]], dim=1\n            )\n            gate = self.gate_fn(nft).sigmoid()\n            attn_out = self.gatlayer(g, x)\n            node_num = g.num_nodes()\n            gated_out = (\n                (gate.view(-1) * attn_out.view(-1, self.out_feats).T).T\n            ).view(node_num, self.num_heads, self.out_feats)\n            gated_out = gated_out.mean(1)\n            merge = self.merger_layer(torch.cat([x, gated_out], dim=1))\n            return merge\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T06:54:31.725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import dgl\nimport dgl.function as fn\nimport dgl.nn as dglnn\nimport numpy as np\nimport scipy.sparse as sparse\nimport torch\nimport torch.nn as nn\nfrom dgl.base import DGLError\nfrom dgl.nn.functional import edge_softmax\n\n\nclass GraphGRUCell(nn.Module):\n    \"\"\"Graph GRU unit which can use any message passing\n    net to replace the linear layer in the original GRU\n    Parameter\n    ==========\n    in_feats : int\n        number of input features\n\n    out_feats : int\n        number of output features\n\n    net : torch.nn.Module\n        message passing network\n    \"\"\"\n\n    def __init__(self, in_feats, out_feats, net):\n        super(GraphGRUCell, self).__init__()\n        self.in_feats = in_feats\n        self.out_feats = out_feats\n        self.dir = dir\n        # net can be any GNN model\n        self.r_net = net(in_feats + out_feats, out_feats)\n        self.u_net = net(in_feats + out_feats, out_feats)\n        self.c_net = net(in_feats + out_feats, out_feats)\n        # Manually add bias Bias\n        self.r_bias = nn.Parameter(torch.rand(out_feats))\n        self.u_bias = nn.Parameter(torch.rand(out_feats))\n        self.c_bias = nn.Parameter(torch.rand(out_feats))\n\n    def forward(self, g, x, h):\n        r = torch.sigmoid(self.r_net(g, torch.cat([x, h], dim=1)) + self.r_bias)\n        u = torch.sigmoid(self.u_net(g, torch.cat([x, h], dim=1)) + self.u_bias)\n        h_ = r * h\n        c = torch.sigmoid(\n            self.c_net(g, torch.cat([x, h_], dim=1)) + self.c_bias\n        )\n        new_h = u * h + (1 - u) * c\n        return new_h\n\n\nclass StackedEncoder(nn.Module):\n    \"\"\"One step encoder unit for hidden representation generation\n    it can stack multiple vertical layers to increase the depth.\n\n    Parameter\n    ==========\n    in_feats : int\n        number if input features\n\n    out_feats : int\n        number of output features\n\n    num_layers : int\n        vertical depth of one step encoding unit\n\n    net : torch.nn.Module\n        message passing network for graph computation\n    \"\"\"\n\n    def __init__(self, in_feats, out_feats, num_layers, net):\n        super(StackedEncoder, self).__init__()\n        self.in_feats = in_feats\n        self.out_feats = out_feats\n        self.num_layers = num_layers\n        self.net = net\n        self.layers = nn.ModuleList()\n        if self.num_layers <= 0:\n            raise DGLError(\"Layer Number must be greater than 0! \")\n        self.layers.append(\n            GraphGRUCell(self.in_feats, self.out_feats, self.net)\n        )\n        for _ in range(self.num_layers - 1):\n            self.layers.append(\n                GraphGRUCell(self.out_feats, self.out_feats, self.net)\n            )\n\n    # hidden_states should be a list which for different layer\n    def forward(self, g, x, hidden_states):\n        hiddens = []\n        for i, layer in enumerate(self.layers):\n            x = layer(g, x, hidden_states[i])\n            hiddens.append(x)\n        return x, hiddens\n\n\nclass StackedDecoder(nn.Module):\n    \"\"\"One step decoder unit for hidden representation generation\n    it can stack multiple vertical layers to increase the depth.\n\n    Parameter\n    ==========\n    in_feats : int\n        number if input features\n\n    hid_feats : int\n        number of feature before the linear output layer\n\n    out_feats : int\n        number of output features\n\n    num_layers : int\n        vertical depth of one step encoding unit\n\n    net : torch.nn.Module\n        message passing network for graph computation\n    \"\"\"\n\n    def __init__(self, in_feats, hid_feats, out_feats, num_layers, net):\n        super(StackedDecoder, self).__init__()\n        self.in_feats = in_feats\n        self.hid_feats = hid_feats\n        self.out_feats = out_feats\n        self.num_layers = num_layers\n        self.net = net\n        self.out_layer = nn.Linear(self.hid_feats, self.out_feats)\n        self.layers = nn.ModuleList()\n        if self.num_layers <= 0:\n            raise DGLError(\"Layer Number must be greater than 0!\")\n        self.layers.append(GraphGRUCell(self.in_feats, self.hid_feats, net))\n        for _ in range(self.num_layers - 1):\n            self.layers.append(\n                GraphGRUCell(self.hid_feats, self.hid_feats, net)\n            )\n\n    def forward(self, g, x, hidden_states):\n        hiddens = []\n        for i, layer in enumerate(self.layers):\n            x = layer(g, x, hidden_states[i])\n            hiddens.append(x)\n        x = self.out_layer(x)\n        return x, hiddens\n\n\nclass GraphRNN(nn.Module):\n    \"\"\"Graph Sequence to sequence prediction framework\n    Support multiple backbone GNN. Mainly used for traffic prediction.\n\n    Parameter\n    ==========\n    in_feats : int\n        number of input features\n\n    out_feats : int\n        number of prediction output features\n\n    seq_len : int\n        input and predicted sequence length\n\n    num_layers : int\n        vertical number of layers in encoder and decoder unit\n\n    net : torch.nn.Module\n        Message passing GNN as backbone\n\n    decay_steps : int\n        number of steps for the teacher forcing probability to decay\n    \"\"\"\n\n    def __init__(\n        self, in_feats, out_feats, seq_len, num_layers, net, decay_steps\n    ):\n        super(GraphRNN, self).__init__()\n        self.in_feats = in_feats\n        self.out_feats = out_feats\n        self.seq_len = seq_len\n        self.num_layers = num_layers\n        self.net = net\n        self.decay_steps = decay_steps\n\n        self.encoder = StackedEncoder(\n            self.in_feats, self.out_feats, self.num_layers, self.net\n        )\n\n        self.decoder = StackedDecoder(\n            self.in_feats,\n            self.out_feats,\n            self.in_feats,\n            self.num_layers,\n            self.net,\n        )\n\n    # Threshold For Teacher Forcing\n\n    def compute_thresh(self, batch_cnt):\n        return self.decay_steps / (\n            self.decay_steps + np.exp(batch_cnt / self.decay_steps)\n        )\n\n    def encode(self, g, inputs, device):\n        hidden_states = [\n            torch.zeros(g.num_nodes(), self.out_feats).to(device)\n            for _ in range(self.num_layers)\n        ]\n        for i in range(self.seq_len):\n            _, hidden_states = self.encoder(g, inputs[i], hidden_states)\n\n        return hidden_states\n\n    def decode(self, g, teacher_states, hidden_states, batch_cnt, device):\n        outputs = []\n        inputs = torch.zeros(g.num_nodes(), self.in_feats).to(device)\n        for i in range(self.seq_len):\n            if (\n                np.random.random() < self.compute_thresh(batch_cnt)\n                and self.training\n            ):\n                inputs, hidden_states = self.decoder(\n                    g, teacher_states[i], hidden_states\n                )\n            else:\n                inputs, hidden_states = self.decoder(g, inputs, hidden_states)\n            outputs.append(inputs)\n        outputs = torch.stack(outputs)\n        return outputs\n\n    def forward(self, g, inputs, teacher_states, batch_cnt, device):\n        hidden = self.encode(g, inputs, device)\n        outputs = self.decode(g, teacher_states, hidden, batch_cnt, device)\n        return outputs\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T06:54:31.725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import dgl\nimport numpy as np\nimport scipy.sparse as sparse\nimport torch\nimport torch.nn as nn\n\n\nclass NormalizationLayer(nn.Module):\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    # Here we shall expect mean and std be scaler\n    def normalize(self, x):\n        return (x - self.mean) / self.std\n\n    def denormalize(self, x):\n        return x * self.std + self.mean\n\n\ndef masked_mae_loss(y_pred, y_true):\n    mask = (y_true != 0).float()\n    mask /= mask.mean()\n    loss = torch.abs(y_pred - y_true)\n    loss = loss * mask\n    # trick for nans: https://discuss.pytorch.org/t/how-to-set-nan-in-tensor-to-0/3918/3\n    loss[loss != loss] = 0\n    return loss.mean()\n\n\ndef get_learning_rate(optimizer):\n    for param in optimizer.param_groups:\n        return param[\"lr\"]\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T06:54:31.725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_cnt = [0]\n\n\ndef train(\n    model,\n    graph,\n    dataloader,\n    optimizer,\n    scheduler,\n    normalizer,\n    loss_fn,\n    device,\n    args,\n):\n    total_loss = []\n    graph = graph.to(device)\n    model.train()\n    batch_size = args.batch_size\n    for i, (x, y) in enumerate(dataloader):\n        optimizer.zero_grad()\n        # Padding: Since the diffusion graph is precmputed we need to pad the batch so that\n        # each batch have same batch size\n        if x.shape[0] != batch_size:\n            x_buff = torch.zeros(batch_size, x.shape[1], x.shape[2], x.shape[3])\n            y_buff = torch.zeros(batch_size, x.shape[1], x.shape[2], x.shape[3])\n            x_buff[: x.shape[0], :, :, :] = x\n            x_buff[x.shape[0] :, :, :, :] = x[-1].repeat(\n                batch_size - x.shape[0], 1, 1, 1\n            )\n            y_buff[: x.shape[0], :, :, :] = y\n            y_buff[x.shape[0] :, :, :, :] = y[-1].repeat(\n                batch_size - x.shape[0], 1, 1, 1\n            )\n            x = x_buff\n            y = y_buff\n        # Permute the dimension for shaping\n        x = x.permute(1, 0, 2, 3)\n        y = y.permute(1, 0, 2, 3)\n\n        x_norm = (\n            normalizer.normalize(x)\n            .reshape(x.shape[0], -1, x.shape[3])\n            .float()\n            .to(device)\n        )\n        y_norm = (\n            normalizer.normalize(y)\n            .reshape(x.shape[0], -1, x.shape[3])\n            .float()\n            .to(device)\n        )\n        y = y.reshape(y.shape[0], -1, y.shape[3]).float().to(device)\n\n        batch_graph = dgl.batch([graph] * batch_size)\n        output = model(batch_graph, x_norm, y_norm, batch_cnt[0], device)\n        # Denormalization for loss compute\n        y_pred = normalizer.denormalize(output)\n        loss = loss_fn(y_pred, y)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n        optimizer.step()\n        if get_learning_rate(optimizer) > args.minimum_lr:\n            scheduler.step()\n        total_loss.append(float(loss))\n        batch_cnt[0] += 1\n        print(\"\\rBatch: \", i, end=\"\")\n    return np.mean(total_loss)\n\n\ndef eval(model, graph, dataloader, normalizer, loss_fn, device, args):\n    total_loss = []\n    preds, gts = [], []       # changed by me\n    graph = graph.to(device)\n    model.eval()\n    batch_size = args.batch_size\n    for i, (x, y) in enumerate(dataloader):\n        # Padding: Since the diffusion graph is precmputed we need to pad the batch so that\n        # each batch have same batch size\n        if x.shape[0] != batch_size:\n            x_buff = torch.zeros(batch_size, x.shape[1], x.shape[2], x.shape[3])\n            y_buff = torch.zeros(batch_size, x.shape[1], x.shape[2], x.shape[3])\n            x_buff[: x.shape[0], :, :, :] = x\n            x_buff[x.shape[0] :, :, :, :] = x[-1].repeat(\n                batch_size - x.shape[0], 1, 1, 1\n            )\n            y_buff[: x.shape[0], :, :, :] = y\n            y_buff[x.shape[0] :, :, :, :] = y[-1].repeat(\n                batch_size - x.shape[0], 1, 1, 1\n            )\n            x = x_buff\n            y = y_buff\n        # Permute the order of dimension\n        x = x.permute(1, 0, 2, 3)\n        y = y.permute(1, 0, 2, 3)\n\n        x_norm = (\n            normalizer.normalize(x)\n            .reshape(x.shape[0], -1, x.shape[3])\n            .float()\n            .to(device)\n        )\n        y_norm = (\n            normalizer.normalize(y)\n            .reshape(x.shape[0], -1, x.shape[3])\n            .float()\n            .to(device)\n        )\n        y = y.reshape(x.shape[0], -1, x.shape[3]).to(device)\n\n        batch_graph = dgl.batch([graph] * batch_size)\n        output = model(batch_graph, x_norm, y_norm, i, device)\n        y_pred = normalizer.denormalize(output)\n        preds.append(y_pred.cpu().detach().numpy())   # changed by me\n        gts.append(y.cpu().detach().numpy())          # changed by me\n        loss = loss_fn(y_pred, y)\n        total_loss.append(float(loss))\n    # Concatenate along batch/time for plotting\n    \n    # shape [num_samples, seq_len, num_nodes, out_feats]\n    gts = np.concatenate(gts, axis=0)      # same shape as preds\n    \n    return preds, gts, np.mean(total_loss)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T06:54:31.725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define arguments directly\nclass Args:\n    def __init__(self):\n        self.batch_size = 64\n        self.num_workers = 0\n        self.model = \"dcrnn\"  # Choose between \"dcrnn\" and \"gaan\"\n        self.gpu = 0  # Set to 0 for GPU, -1 for CPU\n        self.diffsteps = 2\n        self.num_heads = 2\n        self.decay_steps = 2000\n        self.lr = 0.01\n        self.minimum_lr = 2e-6\n        self.dataset = \"LA\"  # Choose between \"LA\" and \"BAY\"\n        self.epochs = 100\n        self.max_grad_norm = 5.0\n\n# Create an instance of Args\nargs = Args()\n\n# Load the datasets\nif args.dataset == \"LA\":\n    g = METR_LAGraphDataset()\n    train_data = METR_LATrainDataset()\n    test_data = METR_LATestDataset()\n    valid_data = METR_LAValidDataset()\nelif args.dataset == \"BAY\":\n    g = PEMS_BAYGraphDataset()\n    train_data = PEMS_BAYTrainDataset()\n    test_data = PEMS_BAYTestDataset()\n    valid_data = PEMS_BAYValidDataset()\n\nif args.gpu == -1:\n    device = torch.device(\"cpu\")\nelse:\n    device = torch.device(\"cuda:{}\".format(args.gpu))\n\ntrain_loader = DataLoader(\n    train_data,\n    batch_size=args.batch_size,\n    num_workers=args.num_workers,\n    shuffle=True,\n)\nvalid_loader = DataLoader(\n    valid_data,\n    batch_size=args.batch_size,\n    num_workers=args.num_workers,\n    shuffle=True,\n)\ntest_loader = DataLoader(\n    test_data,\n    batch_size=args.batch_size,\n    num_workers=args.num_workers,\n    shuffle=True,\n)\nnormalizer = NormalizationLayer(train_data.mean, train_data.std)\n\nif args.model == \"dcrnn\":\n    batch_g = dgl.batch([g] * args.batch_size).to(device)\n    out_gs, in_gs = DiffConv.attach_graph(batch_g, args.diffsteps)\n    net = partial(\n        DiffConv,\n        k=args.diffsteps,\n        in_graph_list=in_gs,\n        out_graph_list=out_gs,\n    )\nelif args.model == \"gaan\":\n    net = partial(GatedGAT, map_feats=64, num_heads=args.num_heads)\n\ndcrnn = GraphRNN(\n    in_feats=2,\n    out_feats=64,\n    seq_len=12,\n    num_layers=2,\n    net=net,\n    decay_steps=args.decay_steps,\n).to(device)\n\noptimizer = torch.optim.Adam(dcrnn.parameters(), lr=args.lr)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n\nloss_fn = masked_mae_loss\n\nfor e in range(args.epochs):\n    train_loss = train(\n        dcrnn,\n        g,\n        train_loader,\n        optimizer,\n        scheduler,\n        normalizer,\n        loss_fn,\n        device,\n        args,\n    )\n    preds_val, gts_val, valid_loss = eval(\n        dcrnn, g, valid_loader, normalizer, loss_fn, device, args\n    )\n    preds_test, gts_test, test_loss = eval(\n        dcrnn, g, test_loader, normalizer, loss_fn, device, args\n    )\n    print(\n        \"\\rEpoch: {} Train Loss: {} Valid Loss: {} Test Loss: {}\".format(\n            e, train_loss, valid_loss, test_loss\n        )\n    )","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T06:54:31.726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import torch\n# import numpy as np\n# import matplotlib.pyplot as plt\n\n# # Convert to numpy arrays (if not already)\n# preds_np = np.array(preds_test)\n# gts_np = np.array(gts_test)\n\n# print(\"Predictions shape:\", preds_np.shape)  # (108, 12, 13248, 2)\n# print(\"Ground truth shape:\", gts_np.shape)   # (1296, 13248, 2)\n\n# # Reshape ground truth from (1296, 13248, 2) to (108, 12, 13248, 2)\n# num_batches = preds_np.shape[0]        # 108\n# forecast_steps = preds_np.shape[1]       # 12\n# flat_dim = preds_np.shape[2]             # 13248\n# features = preds_np.shape[3]             # 2\n\n# expected_ground_truth_size = num_batches * forecast_steps  # 108*12 = 1296\n# if gts_np.shape[0] != expected_ground_truth_size:\n#     raise ValueError(\"Ground truth first dimension does not match expected (num_batches * forecast_steps)\")\n\n# gts_np_reshaped = gts_np.reshape(num_batches, forecast_steps, flat_dim, features)\n# print(\"Reshaped ground truth shape:\", gts_np_reshaped.shape)  # Should be (108, 12, 13248, 2)\n\n# # For METR-LA, we expect a batch size of 64 and 207 sensors: 64 * 207 = 13248.\n# batch_size = 64\n# num_nodes = 207\n\n# if flat_dim != batch_size * num_nodes:\n#     raise ValueError(\"Flat dimension does not match batch_size*num_nodes\")\n\n# # Select a specific batch (for example, the first batch: batch_idx = 0)\n# batch_idx = 0\n# selected_preds = preds_np[batch_idx]     # shape: (12, 13248, 2)\n# selected_gts   = gts_np_reshaped[batch_idx]  # shape: (12, 13248, 2)\n\n# # Reshape each to (seq_len, batch_size, num_nodes, features)\n# seq_len = forecast_steps  # 12 time steps\n# selected_preds_reshaped = selected_preds.reshape(seq_len, batch_size, num_nodes, features)\n# selected_gts_reshaped   = selected_gts.reshape(seq_len, batch_size, num_nodes, features)\n\n# # Choose a specific sample (from the batch) and a sensor to plot.\n# sample_idx = 0    # choose the first sample in the batch (0 <= sample_idx < 64)\n# sensor_idx = 10   # choose sensor index 10 (0 <= sensor_idx < 207)\n\n# # Extract the time series for the chosen sensor and sample.\n# # We use the first feature (index 0) assuming it represents traffic speed.\n# pred_series = selected_preds_reshaped[:, sample_idx, sensor_idx, 0]  # shape: (seq_len,)\n# gt_series   = selected_gts_reshaped[:, sample_idx, sensor_idx, 0]      # shape: (seq_len,)\n\n# # Create a time axis for the forecast horizon.\n# time_axis = np.arange(seq_len)\n\n# # Plot the results.\n# plt.figure(figsize=(10, 4))\n# plt.plot(time_axis, gt_series, label=\"Ground Truth\", color=\"blue\", linewidth=2)\n# plt.plot(time_axis, pred_series, label=\"DCRNN Prediction\", color=\"orange\", linestyle=\"--\", linewidth=2)\n# plt.xlabel(\"Forecast Time Step\")\n# plt.ylabel(\"Traffic Speed (mph)\")\n# plt.title(f\"Traffic Speed Forecast at Sensor {sensor_idx} (Sample {sample_idx}, Batch {batch_idx})\")\n# plt.legend()\n# plt.tight_layout()\n# plt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T06:54:31.726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Suppose you already have:\n# preds_test -> shape (108, 12, 13248, 2)\n# gts_test   -> shape (1296, 13248, 2)\n# and you have confirmed 64*207 = 13248, etc.\n\npreds_np = np.array(preds_test)\ngts_np   = np.array(gts_test)\n\nnum_batches, forecast_steps, flat_dim, features = preds_np.shape  # (108, 12, 13248, 2)\nprint(\"Predictions shape:\", preds_np.shape)\nprint(\"Ground truth shape:\", gts_np.shape)\n\n# Reshape ground truth to match predictions' shape on the time dimension\nexpected_ground_truth_size = num_batches * forecast_steps  # 108*12 = 1296\nif gts_np.shape[0] != expected_ground_truth_size:\n    raise ValueError(\"Ground truth shape mismatch.\")\n\ngts_np_reshaped = gts_np.reshape(num_batches, forecast_steps, flat_dim, features)\nprint(\"Reshaped ground truth shape:\", gts_np_reshaped.shape)\n\n# Merge all batches into a single time dimension: (num_batches * forecast_steps, batch_size, num_nodes, features)\n# In your case, batch_size=64, num_nodes=207 -> flat_dim = 13248\npreds_merged = preds_np.reshape(num_batches * forecast_steps, 64, 207, features)\ngts_merged   = gts_np_reshaped.reshape(num_batches * forecast_steps, 64, 207, features)\n\n# Pick a single sample in the batch and a single sensor\nsample_idx = 0   # which of the 64 samples you want to see\nsensor_idx = 10  # which sensor among the 207\n\n# Extract time series across the entire test set\npred_series = preds_merged[:, sample_idx, sensor_idx, 0]  # shape: (num_batches*forecast_steps,)\ngt_series   = gts_merged[:, sample_idx, sensor_idx, 0]\n\n# ---------------------------------------------------------\n# Example: plotting only the first 24 hours \n# (assuming each step is 5 minutes -> 12 steps/hour -> 288 steps/day)\n# If your data actually covers exactly 24 hrs total, skip slicing.\n# ---------------------------------------------------------\nsteps_per_hour = 12  # e.g., 5-min intervals -> 12 steps in 1 hour\nsteps_24hrs    = 24 * steps_per_hour  # 288\n\n# Make sure your total length is >= 288 if you want 24 hours\nmax_t = min(steps_24hrs, len(pred_series))\npred_series_24h = pred_series[:max_t]\ngt_series_24h   = gt_series[:max_t]\n\n# Create time axis in hours (0..24)\ntime_axis = np.linspace(0, 24, max_t, endpoint=False)\n\nplt.figure(figsize=(10,4))\nplt.plot(time_axis, gt_series_24h, label=\"Ground Truth\", color=\"blue\", linewidth=2)\nplt.plot(time_axis, pred_series_24h, label=\"DCRNN Prediction\", color=\"orange\", linestyle=\"--\", linewidth=2)\nplt.xlabel(\"Time (Hours)\")\nplt.ylabel(\"Traffic Speed (mph)\")\nplt.title(f\"24-Hour Forecast - Sensor {sensor_idx}, Sample {sample_idx}\")\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-06T06:54:31.726Z"}},"outputs":[],"execution_count":null}]}